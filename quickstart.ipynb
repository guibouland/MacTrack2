{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><p style=\"text-align: center;\">Quickstart for MacTrack2</p></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through this file, you can find all the information you need to make this project your own. Don't forget to create your Python environment with the packages available in the `environment.txt` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> WARNING! When you need to make actions, the details will be preceded by this style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "\n",
    "* [How to create your own model](#chapter1)  \n",
    "  * [Dataset](#dataset)\n",
    "  * [Training](#training)\n",
    "  * [Testing](#testing)\n",
    "  * [Model summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create your own model <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset <a class=\"anchor\" id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need a dataset to create your model and a *models* folder to store it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dirs = [\n",
    "    \"model\",\n",
    "    \"model/dataset\",\n",
    "    \"model/dataset/train\",\n",
    "    \"model/dataset/train/train_x\",\n",
    "    \"model/dataset/train/train_y\",\n",
    "    \"model/dataset/test\",\n",
    "    \"model/dataset/test/test_x\",\n",
    "    \"model/dataset/test/test_y\",\n",
    "    \"model/models\",\n",
    "]\n",
    "\n",
    "for d in dirs:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dataset is essential to create your model, you need to add the following :  \n",
    "> - `train_x` : a training set of images that you hand-cut yourself using [Fiji](https://imagej.net/software/fiji/downloads)\n",
    "> - `train_y` : the masks for each segmented frame in a zip file containing all the ROI files\n",
    "> - `test_x` and `test_y` : you should do the same, it will serve to test the model that has been trained on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of an image that will be placed in the *x* sets (wether it is the training or the test set) on the left. And on the right, each yellow lining represent a ROI (region of interest). Those are saved in a zip file and in the *y* sets.  \n",
    "<p align=\"center\">\n",
    "  <img src=\"images/example_frame.jpg\" alt=\"frame_ex\" width=\"45%\"/>\n",
    "  <img src=\"images/example_frame_ROI.jpg\" alt=\"ROI_ex\" width=\"45%\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TODO : DOC ABOUT FIJI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `kartezio` package that will help us build the model need two other files : `META.json` and `dataset.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The META file is here to help the package recognize the formats of the different objects in the dataset folder.  \n",
    "> You need to run the following to help you create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "meta_path = \"model/dataset/META.json\"\n",
    "\n",
    "# Content of the JSON file\n",
    "meta_data = {\n",
    "    \"name\": \"Macrophage\",\n",
    "    \"scale\": 1.0,\n",
    "    \"label_name\": \"macrophage\",\n",
    "    \"mode\": \"dataframe\",\n",
    "    \"input\": {\n",
    "        \"type\": \"image\",\n",
    "        \"format\": \"hsv\"\n",
    "    },\n",
    "    \"label\": {\n",
    "        \"type\": \"roi\",\n",
    "        \"format\": \"polygon\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the JSON file with the content in it\n",
    "with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta_data, f, indent=4)\n",
    "\n",
    "print(f\"Fichier {meta_path} créé avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file is here to help kartezio read your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Set_up.dataset_csv import create_dataset_csv\n",
    "create_dataset_csv(input_folder='model/dataset', output_csv='model/dataset/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your two files are now created and located in the `model/dataset` folder. We can now train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the structure kartezio needs to function correctly, we can create and train a model using the `create_segmentation_model` function of the kartezio package. You can find the following code in the `Set_up/train_model.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kartezio.apps.segmentation import create_segmentation_model\n",
    "from kartezio.endpoint import EndpointThreshold\n",
    "from kartezio.dataset import read_dataset\n",
    "from kartezio.training import train_model\n",
    "\n",
    "DATASET = \"model/dataset\"\n",
    "OUTPUT = \"model/models\"\n",
    "\n",
    "generations = 1000\n",
    "_lambda = 5\n",
    "frequency = 5\n",
    "rate = 0.1\n",
    "print(rate)\n",
    "model = create_segmentation_model(\n",
    "    generations,\n",
    "    _lambda,\n",
    "    inputs=3,\n",
    "    nodes=30,\n",
    "    node_mutation_rate=rate,\n",
    "    output_mutation_rate=rate,\n",
    "    outputs=1,\n",
    "    fitness=\"IOU\",\n",
    "    endpoint=EndpointThreshold(threshold=4)\n",
    ")\n",
    "\n",
    "dataset = read_dataset(DATASET)\n",
    "elite, a = train_model(model, dataset, OUTPUT, callback_frequency=frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing <a class=\"anchor\" id=\"testing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you trained your model, you can test it to see if it gives good prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from kartezio.easy import print_stats\n",
    "from kartezio.dataset import read_dataset\n",
    "from kartezio.fitness import FitnessIOU\n",
    "from kartezio.inference import ModelPool\n",
    "\n",
    "scores_all = {}\n",
    "pool = ModelPool(f\"model/models\", FitnessIOU(), regex=\"*/elite.json\").to_ensemble()\n",
    "dataset = read_dataset(f\"model/dataset\", counting=True)\n",
    "annotations_test = 0\n",
    "annotations_training = 0\n",
    "roi_pixel_areas = []\n",
    "for y_true in dataset.train_y:\n",
    "    n_annotations = y_true[1]\n",
    "    annotations_training += n_annotations\n",
    "for y_true in dataset.test_y:\n",
    "    annotations = y_true[0]\n",
    "    n_annotations = y_true[1]\n",
    "    annotations_test += n_annotations\n",
    "    for i in range(1, n_annotations + 1):\n",
    "        roi_pixel_areas.append(np.count_nonzero(annotations[annotations == i]))\n",
    "print(f\"Total annotations for training set: {annotations_training}\")\n",
    "print(f\"Total annotations for test set: {annotations_test}\")\n",
    "print(f\"Mean pixel area for test set: {np.mean(roi_pixel_areas)}\")\n",
    "\n",
    "\n",
    "scores_test = []\n",
    "scores_training = []\n",
    "for i, model in enumerate(pool.models):\n",
    "    # Test set\n",
    "    _, fitness, _ = model.eval(dataset, subset=\"test\")\n",
    "    scores_test.append(1.0 - fitness)\n",
    "\n",
    "    # Training set\n",
    "    _, fitness, _ = model.eval(dataset, subset=\"train\")\n",
    "    scores_training.append(1.0 - fitness)\n",
    "\n",
    "\n",
    "scores_all[f\"training\"] = scores_training\n",
    "scores_all[f\"test\"] = scores_test\n",
    "print_stats(scores_training, \"IOU\", \"training set\")\n",
    "print_stats(scores_test, \"IOU\", \"test set\")\n",
    "\n",
    "pd.DataFrame(scores_all).to_csv(\"model/scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model summary <a class=\"anchor\" id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can summarize your trained model to understand its structure and behavior. The summary provides insights into the nodes, connections, and parameters of the model. This can help you analyze how the model was built and how it processes data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Set_up.explain_model import summary_model\n",
    "\n",
    "summary = summary_model('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a `csv` file for the nodes that will help you understand better the model build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access other parameters that are not displayed in the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can extract any object from that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
